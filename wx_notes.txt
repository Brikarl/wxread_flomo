《深度学习推荐系统》

王喆
143个笔记

5.5 推荐系统中比模型结构更重要的是什么

◆ 在具体的优化过程中，模型会根据不同用户的喜好，使用不同的影片预览图模板，填充以不同的前景、背景、文字等。通过使用简单的线性“探索与利用”(Exploration＆Exploitation)模型验证哪种组合才是最适合某类用户的个性化海报。

◆ 对推荐系统效果的改进，最有效的方法不是执着地改进那块已经很长的木板，而是发现那块最短的木板，提高整体的效果。

◆ 广义上讲，引入新的有价值信息相当于为推荐系统增加新的“水源”​，而改进模型结构则是对已有“水源”的进一步挖掘。通常，新水源带来的收益更高，开拓难度却小于对已有水源的持续挖掘。

◆ 简单回顾DIN的原理，DIN在经典的深度CTR模型的基础上，在构建特征向量的过程中，对每一类特征加入一个激活单元，这个激活单元的作用类似一个开关，控制了这类特征是否放入特征向量及放入时权重的大小。那这个开关由谁控制呢？它是由被预测广告物品跟这类特征的关系决定的。也就是说，在预测用户u是否喜欢物品i这件事上，DIN只把跟物品i有关的特征考虑进来，其他特征的门会被关上，完全不考虑或者权重很小。那么，阿里巴巴的工程师能够提出将注意力机制应用于深度神经网络的想法是单纯的技术考虑吗？笔者曾与DIN论文的作者进行过交流，发现他们的出发点同样是用户的行为特点。天猫、淘宝作为综合性的电商网站，只有收集与候选物品相关的用户历史行为记录才是有价值的。基于这个出发点，引入相关物品的开关和权重结构，最终发现注意力机制恰巧是能够解释这个动机的最合适的技术结构。反过来，如果单纯从技术角度出发，为了验证注意力机制是否有效而应用注意力机制，则有“本末倒置”的嫌疑，因为这不是业界解决问题的常规思路，而是试探性的技术验证过程，这种纯“猜测”型的验证无疑会大幅增加工作量。


5.6 冷启动的解决办法

◆ (1)基于规则的冷启动过程。(2)丰富冷启动过程中可获得的用户和物品特征。(3)利用主动学习、迁移学习和“探索与利用”机制。

◆ 在冷启动过程中，由于数据的缺乏，个性化推荐引擎无法有效工作，自然可以让系统回退到“前推荐系统”时代，采用基于规则的推荐方法。例如，在用户冷启动场景下，可以使用“热门排行榜”​“最近流行趋势”​“最高评分”等榜单作为默认的推荐列表。

◆ 利用点击率等目标构建一个用户属性的决策树，在每个决策树的叶节点建立冷启动榜单，在新用户完成注册后，根据用户有限的注册信息，寻找决策树上对应的叶节点榜单，完成用户冷启动过程。

◆ Airbnb是全球最大的短租房中介平台。在新上线短租房时，Airbnb会根据该房屋的属性对该短租房指定一个“聚类”​，位于同样“聚类”中的房屋会有类似的推荐规则。那么，为冷启动短租房指定“聚类”所依靠的规则有如下三条：(1)同样的价格范围。(2)相似的房屋属性（面积、房间数等）​。(3)距目标房源的距离在10公里以内。找到最符合上述规则的3个相似短租房，根据这3个已有短租房的聚类定位冷启动短租房的聚类。通过Airbnb的例子可以知道，基于规则的冷启动方法更多依赖的是领域专家对业务的洞察。在制定冷启动规则时，需要充分了解公司的业务特点，充分利用已有数据，才能让冷启动规则合理且高效。

◆ 在历史数据特征缺失的情况下，推荐系统仍然可以凭借用户和物品的属性特征完成较粗粒度的推荐。这类属性特征主要包括以下几类：
(1)用户的注册信息。包括基本的人口属性信息（年龄、性别、学历、职业等）和通过IP地址、GPS信息等推断出的地理信息。
(2)第三方DMP（Data Management Platform，数据管理平台）提供的用户信息。国外的BlueKai、Nielsen，国内的Talking Data等公司都提供匹配率非常高的数据服务，可以极大地丰富用户的属性特征。这些第三方数据管理平台不仅可以提供基本的人口属性特征，通过与大量应用、网站的数据交换，甚至可以提供脱敏的用户兴趣、收入水平、广告倾向等一系列的高阶特征。
(3)物品的内容特征。在推荐系统中引入物品的内容相关特征是有效地解决“物品冷启动”的方法。物品的内容特征可以包括物品的分类、标签、描述文字等。具体到不同的业务领域，还可以有更丰富的领域相关内容特征。例如，在视频推荐领域，视频的内容特征可包括，该视频的演员、年代、风格，等等。
(4)引导用户输入的冷启动特征。有些应用会在用户第一次登录时引导用户输入一些冷启动特征。例如，一些音乐类应用会引导用户选择“音乐风格”；一些视频类应用会引导用户选择几部喜欢的电影。这些都是通过引导页面来完成丰富冷启动特征的工作。

◆ 2024/08/07发表想法

聚类最大，收益越大。

原文：主动学习的学习目标是尽可能快速地定位所有物品可能的打分。可以看到，所有影片聚成了a、b、c、d4类，聚类的大小不一。那么，以主动学习的思路，应该在下一次的推荐中选择哪部影片呢？答案是应该选择最大聚类d的中心节点作为推荐影片，因为通过主动问询用户对d中心节点的打分，可以得到用户对最大聚类d的反馈，使推荐系统的收益最大。严格地讲，应定义推荐系统的损失函数，从而精确地评估推荐不同影片获得的损失下降收益。这里仅以此例帮助读者领会主动学习的原理。

◆ 主动学习的学习目标是尽可能快速地定位所有物品可能的打分。可以看到，所有影片聚成了a、b、c、d4类，聚类的大小不一。那么，以主动学习的思路，应该在下一次的推荐中选择哪部影片呢？答案是应该选择最大聚类d的中心节点作为推荐影片，因为通过主动问询用户对d中心节点的打分，可以得到用户对最大聚类d的反馈，使推荐系统的收益最大。严格地讲，应定义推荐系统的损失函数，从而精确地评估推荐不同影片获得的损失下降收益。这里仅以此例帮助读者领会主动学习的原理。

◆ 俗语说“巧妇难为无米之炊”​，冷启动问题的难点就在于没有米，还要让“巧妇”​（算法工程师）做一顿饭。解决这个困局的两种思路：(1)虽然没有米，但不可能什么吃的都没有，先弄点粗粮尽可能做出点吃的再说。这就要求冷启动算法在没有精确的历史行为数据的情况下，利用一些粗粒度的特征、属性，甚至其他领域的知识进行冷启动推荐。(2)边做吃的边买米，快速度过“无米”的阶段。这种解决问题的思路是先做出点吃的，卖了吃的换钱买米，将饭越做越好，米越换越多。这就是利用主动学习、“探索与利用”机制，甚至强化学习模型解决冷启动问题的思路。


5.7 探索与利用

◆ 《淮南子》中有一句话非常有名：​“先王之法，不涸泽而渔，不焚林而猎。​”否定的是做事只顾眼前利益，不做长远打算的做法。那么在推荐系统中，有没有所谓的眼前利益和长远打算呢？当然是有的。所有的用户和物品历史数据就像是一个鱼塘，如果推荐系统只顾着捞鱼，不往里面补充新的鱼苗，那么总有一天鱼塘中鱼的资源会逐渐枯竭，以至最终无鱼可捞。

◆ 解决“探索与利用”问题目前主要有三大类方法。(1)传统的探索与利用方法：这类方法将问题简化成多臂老虎机问题。主要的算法有ε-Greedy（ε贪婪）、Thompson Sampling（汤普森采样）和UCB。该类解决方法着重解决新物品的探索和利用，方法中并不考虑用户、上下文等因素，因此是非个性化的探索与利用方法。(2)个性化的探索与利用方法：该类方法有效地结合了个性化推荐特点和探索与利用的思想，在考虑用户、上下文等因素的基础上进行探索与利用的权衡，因此被称为个性化探索与利用方法。(3)基于模型的探索与利用方法：该类方法将探索与利用的思想融入推荐模型之中，将深度学习模型和探索与利用的思想有效结合，是近年来的热点方向。

◆ 这里ε的值代表对“探索”的偏好程度，每次以概率ε去“探索”​，以(1-ε)的概率来“利用”​，基于被选择的物品的回报更新该物品的回报期望

◆ CTR的场景和掷硬币都可以看作伯努利过程（可以把CTR问题看成一个掷偏心硬币的过程，点击率就是硬币正面的概率）​，因此Thompson Sampling算法同样适用于CTR等推荐场景。

◆ 探索与利用算法在推荐系统中的应用场景是多样的，主要包括以下3个方面：(1)物品冷启动。对新加入的物品或者长久没有互动信息的长尾物品来说，探索与利用算法对新物品和长尾物品有天然的倾向性，因此可以帮助这类物品快速收集用户反馈，快速度过冷启动期，并在较少伤害系统整体收益的前提下，快速找到有潜力的物品，丰富优质的物品候选集。(2)发掘用户新兴趣。本节开头已经介绍过，如果推荐系统总是利用现有数据为用户推荐物品，相当于对用户的已发掘兴趣进行“涸泽而渔”的利用，短期内用户可能满足于当前的推荐结果，但很可能快速疲倦并离开。为了发掘用户新兴趣，推荐系统有必要进行一定程度的探索，维持用户的长期兴趣。另外，用户兴趣本身也在不断的改变和进化，需要通过探索不断抓住用户兴趣改变的趋势。(3)增加结果多样性。探索与利用也是增加推荐结果多样性的手段。增加结果多样性对于推荐系统的好处主要有两方面，一方面是让用户能明显感觉到结果的丰富性；另一方面是减少大量同质化内容同时出现时用户的厌倦情绪。


第6章 深度学习推荐系统的工程实现

◆ 从工程的角度来看推荐系统，可以将其分为两大部分：数据部分和模型部分。数据部分主要指推荐系统所需数据流的相关工程实现；模型部分指的是推荐模型的相关工程实现，根据模型应用阶段的不同，可进一步分为离线训练部分和线上服务部分。


6.2 推荐模型离线训练之Spark MLlib

◆ 笔者经常把推荐系统的推荐过程比喻成做菜的过程。一位大厨能不能做出一桌好菜，关键点有3个：(1)原材料如何，丰富不丰富，新鲜不新鲜。(2)厨艺好不好，有没有丰富的经验。(3)现场发挥。能不能物尽其用，充分展现厨艺。对应地，推荐系统的数据流提供的就是做菜用的“原材料”​，数据流提供的数据丰富程度、实时程度，就是原材料的“丰富”和“新鲜”程度；推荐系统离线训练模型的过程就是大厨台下精进厨艺的过程，训练得越充分，试过的原材料种类越多，厨艺就越高；而推荐系统的线上推荐过程就是大厨“展现厨艺”的过程，好的厨艺不仅需要现场的食材跟台下的同样丰富和新鲜，更需要烹饪的过程不拖泥带水，根据食客的口味做出最合适的佳肴。


6.6 工程与理论之间的权衡

◆ 单纯从技术角度考虑，既然已经决定升级到TensorFlow 平台，理论上没必要再花时间利用Spark平台研发新模型。这里需要搞清楚的问题有两个。(1)再成熟的平台也需要整个团队磨合调试较长时间，绝不可能刚迁移至TensorFlow就让它支持重要的业务逻辑。(2)技术平台的升级换代应作为技术团队的内部项目，最好对其他团队透明，不应成为减缓对业务支持的直接理由。因此，从工程进度和风险角度考虑，第2个技术途径应成为更符合工程实际和公司实际的选择。

◆ 一方面是程序本身的优化。笔者在带实习生时，经常遇到一些实习生抱怨Spark跑得太慢，究其原因，是因为他们对Spark的shuffle机制没有深入了解，写的程序包含大量触发shuffle的操作，容易导致大量的数据倾斜问题。这样的问题本身并不涉及技术上的“权衡”​，而是应该夯实自己的技术功底，尽量通过技术上的“优化”提升模型的训练效率和实时性。


7.1 离线评估方法与基本评价指标

◆ 但也存在明显的缺陷：当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。例如，如果负样本占99%，那么分类器把所有样本都预测为负样本也可以获得99%的准确率。

◆ F1-score是精确率和召回率的调和平均值，


7.5 快速线上评估方法——Interleaving

◆ 在传统的A/B 测试中，Netflix 会选择两组订阅用户：一组接受排序算法A的推荐结果，另一组接受排序算法B的推荐结果。
而在Interleaving 方法中，只有一组订阅用户，这些订阅用户会收到通过混合算法A和B的排名生成的交替排名。
这就使得用户可以在一行里同时看到算法A 和B的推荐结果（用户无法区分一个物品是由算法A推荐的还是由算法B推荐的），进而通过计算观看时长等指标来衡量到底是算法A的效果好还是算法B的效果好。
当然，在使用Interleaving方法进行测试的时候，必须考虑位置偏差的存在，避免来自算法A的视频总排在第一位。因此，需要以相等的概率让算法A 和算法B交替领先。这类似于在野球场打球时，两个队长先通过扔硬币的方式决定谁先选人，再交替选队员的过程（如图7-9所示）。


8.3 YouTube深度学习视频推荐系统

◆ 在预测某用户的视频候选集时，先得到该用户的Embedding向量，再在视频Embedding向量空间中利用局部敏感哈希等方法搜索该用户Embedding向量的Top K近邻，就可以快速得到k个候选视频集合。

◆ 相比候选集生成模型需要对几百万候选集进行粗筛，排序模型只需对几百个候选视频进行排序，因此可以引入更多特征进行精排。具体地讲，输入层从左至右的特征依次是：(1)当前候选视频的Embedding(impression video ID embedding)。(2)用户观看过的最后N 个视频Embedding的平均值(watched video IDsaverage embedding)。(3)用户语言的Embedding 和当前候选视频语言的Embedding(languageembedding)。(4)该用户自上次观看同频道视频的时间(time since last watch)。(5)该视频已经被曝光给该用户的次数(＃previous impressions)。

◆ 上面5个特征中，前3个的含义是直观的，这里重点介绍第4个和第5个特征。因为这两个特征很好地引入了YouTube对用户行为的观察。第4个特征time since last watch表达的是用户观看同类视频的间隔时间。从用户的角度出发，假如某用户刚看过“DOTA比赛经典回顾”这个频道的视频，那么用户大概率会继续看这个频道的视频，该特征很好地捕捉到了这一用户行为。第5个特征＃previous impressions则在一定程度上引入了5.7节介绍的“探索与利用”机制，避免同一个视频对同一用户的持续无效曝光，尽量增加用户看到新视频的可能性。

◆ 经过三层ReLU网络之后，排序模型的输出层与候选集生成模型又有所不同。候选集生成模型选择softmax作为其输出层，而排序模型选择加权逻辑回归作为模型输出层。与此同时，模型服务阶段的输出层选择的是e(Wx+b)函数。YouTube为什么分别在训练和服务阶段选择了不同的输出层函数呢？从YouTube的商业模式出发，增加用户观看时长才是其推荐系统最主要的优化目标，所以在训练排序模型时，每次曝光期望观看时长(expected watch time per impression)应该作为更合理的优化目标。因此，为了能直接预估观看时长，YouTube将正样本的观看时长作为其样本权重，用加权逻辑回归进行训练，就可以让模型学到用户观看时长的信息。

◆ 可以看出，变量Odds 本质上的物理意义就是每次曝光期望观看时长，这正是排序模型希望优化的目标。因此，利用加权逻辑回归进行模型训练，利用eWx+b进行模型服务是最符合优化目标的技术实现。

◆ 在对训练集的预处理过程中，YouTube没有采用原始的用户日志，而是对每个用户提取等数量的训练样本，这是为什么呢？YouTube这样做的目的是减少高度活跃用户对模型损失的过度影响，使模型过于偏向活跃用户的行为模式，忽略数量更广大的长尾用户的体验。

◆ 在处理测试集的时候，YouTube为什么不采用经典的随机留一法(random holdout)，而是一定要以用户最近一次观看的行为作为测试集呢？只留最后一次观看行为做测试集主要是为了避免引入未来信息(futureinformation)，产生与事实不符的数据穿越问题。

◆ 该特征本身并不包含任何信息，但当该特征在深度神经网络中与其他特征做交叉时，就起到了时间戳的作用，通过这个时间戳和其他特征的交叉，保存了其他特征随时间变化的权重，也就让最终的预测包含了时间趋势的信息

◆ YouTube显然没有采用这种方法，笔者推测该方法效果不好的原因是这种做法会导致Example Age的分布过于分散，在训练过程中会包含刚上传的视频，也会包含上传已经1年，甚至5年的视频，这会导致Example Age无法集中描述近期的变化趋势。


参考文献

◆ [6]Gai,Kun,et al.Learning piece-wise linear models from large scale data for ad click prediction.arXiv preprint arXiv:1704.05194 (2017).[7]Zhou,Guorui,et al.Deep interest network for click-through rate prediction.Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery＆Data Mining.2018.[8]Zhou,Guorui,et al.Deep interest evolution network for click-through rate prediction.Proceedings of the AAAI Conference on Artificial Intelligence.Vol.33.2019.

-- 来自微信读书